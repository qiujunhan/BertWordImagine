{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from importlib import import_module\n",
    "from models import bert\n",
    "import torch.nn.functional as F\n",
    "class Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.model_name = 'bert'\n",
    "\n",
    "        self.mlb_path = dataset +'/data/bert/mlb_model.pickle'\n",
    "        with open(self.mlb_path, 'rb') as f:\n",
    "            self.mlb = pickle.load(f)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n",
    "\n",
    "        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes =self.mlb.classes_.shape[0]                    # 类别数\n",
    "        self.num_epochs = 2                                             # epoch数\n",
    "        self.batch_size = 64                                           # mini-batch大小\n",
    "        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)\n",
    "        self.bert_path = './bert_pretrain'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.hidden_size = 768\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]  # 输入的句子\n",
    "        mask = x[2]  # 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]\n",
    "        _, pooled = self.bert(context, attention_mask=mask, output_all_encoded_layers=False)\n",
    "        out = self.fc(pooled)\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_input(content):\n",
    "    pad_size = 32\n",
    "    PAD, CLS = '[PAD]', '[CLS]'  # padding符号, bert中综合信息符号\n",
    "    token = config.tokenizer.tokenize(content)\n",
    "    token = [CLS] + token\n",
    "    seq_len = len(token)\n",
    "    mask = []\n",
    "    token_ids = config.tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "    if pad_size:\n",
    "        if len(token) < pad_size:\n",
    "            mask = [1] * len(token_ids) + [0] * (pad_size - len(token))\n",
    "            token_ids += ([0] * (pad_size - len(token)))\n",
    "        else:\n",
    "            mask = [1] * pad_size\n",
    "            token_ids = token_ids[:pad_size]\n",
    "            seq_len = pad_size\n",
    "    x = torch.LongTensor([token_ids]).to(config.device)\n",
    "    # pad前的长度(超过pad_size的设为pad_size)\n",
    "    seq_len = torch.LongTensor([seq_len]).to(config.device)\n",
    "    mask = torch.LongTensor([mask]).to(config.device)\n",
    "    return (x, seq_len, mask)\n",
    "def get_preview(predicted,config,topn = 20):\n",
    "    predicted = predicted.cpu().numpy()[0]\n",
    "    if topn >0 :\n",
    "        top_n = np.argsort(predicted)[:-topn:-1]\n",
    "    else:\n",
    "        top_n = np.where(predicted>0)\n",
    "    probability = predicted[top_n]\n",
    "    integrate_array = []\n",
    "    for i in range(len(top_n)):\n",
    "        index = np.array([top_n[i]])\n",
    "        prob = probability[i]\n",
    "        zero_array = np.zeros((1,config.mlb.classes_.size))\n",
    "        zero_array[-1,index]=1\n",
    "        proba_encoding = zero_array.reshape(-1)\n",
    "        predict_decoding = config.mlb.inverse_transform(np.array([proba_encoding]))\n",
    "        predict_decoding = [predict_decoding[0][0]]\n",
    "        # print(predict_decoding)\n",
    "        predict_decoding.append(prob)\n",
    "        integrate_array.append(predict_decoding)\n",
    "    return (integrate_array)\n",
    "\n",
    "\n",
    "\n",
    "dataset = 'data'  # 数据集\n",
    "\n",
    "model_name = \"bert\"\n",
    "x = bert\n",
    "config = x.Config(dataset)\n",
    "config.device=\"cpu\"\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "\n",
    "\n",
    "model = x.Model(config).to(config.device)\n",
    "model.load_state_dict(torch.load(\"model_backup/0.010500757530200897_bert.pth\"))\n",
    "model.to(config.device)\n",
    "model.eval()\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1girl', 1.2181752], ['long_hair', 0.5462417], ['solo', 0.26949114], ['looking_at_viewer', 0.17081736], ['breasts', -0.2574032], ['bangs', -0.62327063], ['blush', -0.6945634], ['large_breasts', -1.1485584], ['smile', -1.1619827], ['open_mouth', -1.317502], ['black_hair', -1.3452197], ['thighhighs', -1.4484718], ['hair_ornament', -1.4674329], ['bare_shoulders', -1.4879841], ['skirt', -1.4976889], ['cleavage', -1.5159113], ['navel', -1.5772165], ['blue_eyes', -1.5795715], ['brown_hair', -1.6344185], ['sitting', -1.6435425], ['animal_ears', -1.7106385], ['shirt', -1.7573078], ['short_hair', -1.7742445], ['letterboxed', -1.8166447], ['purple_eyes', -1.825652], ['long_sleeves', -1.8973978], ['gloves', -1.9260623], ['red_eyes', -1.9292862], ['underwear', -1.9514407], ['flower', -1.9817958], ['blonde_hair', -2.0235577], ['simple_background', -2.0355763], ['twintails', -2.050722], ['swimsuit', -2.0732186], ['dress', -2.0780213], ['very_long_hair', -2.1354082], ['panties', -2.1449835], ['bow', -2.145988], ['white_background', -2.147825], ['holding', -2.1571348], ['school_uniform', -2.1751702], ['jewelry', -2.1940176], ['japanese_clothes', -2.194695], ['ribbon', -2.1985354], ['collarbone', -2.2280848], ['bikini', -2.2289019], ['white_hair', -2.2370594], ['hair_between_eyes', -2.2534115], ['pantyhose', -2.3044882]]\n"
     ]
    }
   ],
   "source": [
    "input_ = \"electric_fan\"\n",
    "\n",
    "input_ = get_input(input_)\n",
    "pred = model(input_)\n",
    "predicted = pred.detach()\n",
    "output = get_preview(predicted,config,50)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
